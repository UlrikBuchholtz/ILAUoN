<?xml version="1.0" encoding="UTF-8"?>

<!--********************************************************************
Copyright 2023 Ulrik Buchholtz

Permission is granted to copy, distribute and/or modify this document
under the terms of the GNU Free Documentation License, Version 1.3 or
any later version published by the Free Software Foundation.  A copy of
the license is included in gfdl.xml.
*********************************************************************-->

<section xml:id="matrix-coords">
  <title>Invertible matrices and Coordinate Systems</title>

  <objectives>
    <ol>
      <li>Learn to use invertible matrices to convert between coordinate systems.</li>
      <li>Learn to represent linear transformations with respect to given bases.</li>
      <li><em>Recipes:</em> compute the <m>(\cB,\cC)</m>-matrix of a linear transformation.</li>
      <li><em>Vocabulary:</em> <term><m>(\cB,\cC)</m>-matrix</term>.</li>
    </ol>
  </objectives>

  <p>
    In this section, we study matrix representations for linear transformations with respect to bases for the domain and the codomain. We'll also get another perspective on bases in terms of the linear transformations they represent, and we'll see how to convert between different coordinate systems using matrices and their inverses.
  </p>

  <fact hide-type="true" xml:id="linear-trans-pick-columns">
    <title>Bases and one-to-one linear transformations</title>
    <p>
      If <m>B</m> is an <m>m\times n</m> matrix with columns <m>v_1,v_2,\ldots,v_n</m>,
      then <m>\cB = (v_1,\ldots,v_n)</m> is a basis for the column span <m>V = \Col(B)</m>
      if and only if the linear transformation <m>T : \R^n \to \R^m</m>,
      <m>T(x)=Bx</m> is one-to-one.
    </p>
  </fact>

  <p>
    Indeed, the columns of <m>B</m> span <m>V</m> by definition, and they're
    linearly independent if and only if <m>T</m> is one-to-one, using
    <xref ref="matrix-trans-one-to-one"/>.
  </p>

  <p>
    In particular, a list <m>\cB = (v_1,\ldots,v_n)</m> of vectors in <m>\R^n</m>
    forms a basis for all of <m>\R^n</m> if and only if the square <m>n\times n</m>
    matrix <m>B</m> with columns <m>v_1,\ldots,v_n</m> is invertible.
    These columns are clearly the coordinate vectors of the <m>v_i</m>
    with respect to the standard basis <m>\cE = (e_1,\ldots,e_n)</m> for <m>\R^n</m>.
    Conversely, the columns of the inverse matrix <m>B^{-1}</m>
    are the <m>\cB</m>-coordinates of the standard basis vectors:
    <me>
      B^{-1} = \mat[c]{| | ,, |; {}_\cB[e_1] {}_\cB[e_2] \cdots, {}_\cB[e_n]; | | ,, |}.
    </me>
    This is because <m>BB^{-1} = I_n</m>, so <m>B\;{}_\cB[e_i] = e_i</m>,
    which is the definition of <m>{}_\cB[e_i]</m> being the <m>\cB</m>-coordinates
    of <m>e_i</m>.
    Multiplying by <m>B^{-1}</m> and taking linear combinations we get:
  </p>

  <bluebox>
    <p>
      If <m>B</m> is an invertible <m>n\times n</m> square matrix,
      whose columns thus form a basis <m>\cB</m> of <m>\R^n</m>,
      the <m>\cB</m>-coordinates of any vector <m>x\in\R^n</m> is given by
      <me>{}_\cB[x] = B^{-1}x \sptxt{and hence} B\;{}_\cB[x] = x.</me>
      This says that (multiplication by) <em><m>B</m> changes from
      the <m>\cB</m>-coordinates to the usual coordinates</em>,
      and <em><m>B\inv</m> changes from the usual coordinates to
      the <m>\cB</m>-coordinates.</em>
    </p>
  </bluebox>

  <definition xml:id="defn-BCmatrix">
    <idx><h><m>(\cB,\cC)</m>-matrix</h><h>definition of</h></idx>
    <notation><usage>{}_\cC[T]_\cB</usage><description>The <m>(\cB,\cC)</m>-matrix of a linear transformation</description></notation>
    <statement>
      <p>
        Suppose we're given bases <m>\cB = (v_1,\ldots,v_n)</m> for <m>\R^n</m>
        and <m>\cC = (w_1,\ldots,w_m)</m> for <m>\R^m</m>.
        Let <m>T : \R^n \to \R^m</m> be a linear transformation.
        The <term><m>(\cB,\cC)</m>-matrix of <m>T</m></term> is the <m>m\times n</m>
        matrix
        <me>
          {}_\cC[T]_\cB =
          \mat[c]{| | ,, |;
          {}_\cC[T(v_1)] {}_\cC[T(v_2)] \cdots, {}_\cC[T(v_n)];
          | | ,, | }.
        </me>
      </p>
    </statement>
  </definition>

  <p>
    This generalizes the definition of the standard matrix of <m>T</m>:
    If we let <m>\cB=\cE_n</m> and <m>\cC=\cE_m</m> be the standard bases
    for <m>\R^n</m> and <m>\R^m</m>, then <m>{}_{\cE_m}[T]_{\cE_n} = [T]</m>,
    the standard matrix of <m>T</m>.
  </p>

  <p>
    By the discussion above, if <m>\cE</m> is the standard basis for <m>\R^n</m>
    and <m>\cB = (v_1,\ldots,v_n)</m> is another basis for <m>\R^n</m>,
    so the square <m>n\times n</m> matrix <m>B</m> with columns
    <m>v_1,\ldots,v_n</m> is invertible, then
    <me>B = {}_\cE[\Id_{\R^n}]_\cB \sptxt{and}
    B^{-1} = {}_\cB[\Id_{\R^n}]_\cE.</me>
  </p>

  <bluebox>
    <p>
      If <m>B</m> is an invertible <m>n\times n</m> square matrix,
      whose columns thus form a basis <m>\cB</m> of <m>\R^n</m>,
      and <m>C</m> is an invertible <m>m\times m</m> square matrix,
      whose columns thus form a basis <m>\cC</m> of <m>\R^m</m>,
      then the <m>(\cB,\cC)</m>-matrix of a linear transformation
      <m>T : \R^n \to \R^m</m> is given by the matrix product
      <me>{}_\cC[T]_\cB = C^{-1}[T]B,</me>
      where <m>[T]</m> is the standard matrix for <m>T</m>.
    </p>
  </bluebox>

  <p>
    One way to read this formula is right-to-left: The multiplying by
    <m>B</m> converts from <m>/cB</m>-coordinates to standard
    coordinates in <m>\R^n</m>; multiplying by the standard matrix
    <m>[T]</m> then results in the standard coordinates in <m>\R^m</m>
    of the result of acting with the transformation <m>T</m>, while
    finally multiplying by <m>C\inv</m> converts to the
    <m>\cC</m>-coordinates.  Altogether, the matrix product
    <m>C^{-1}[T]B</m> takes <m>\cB</m>-coordinates of a vector
    <m>x \in \R^n</m> to the <m>\cC</m>-coordinates of the image <m>T(x) \in \R^m</m>
  </p>

  <p>
    Conversely, we can recover the standard matrix of <m>T</m> as
    <me>[T] = C \; {}_\cC[T]_\cB \; B\inv;</me> this says that to do
    <m>T</m> in standard coordinates is the same as to first convert
    to <m>\cB</m>-coordinates, then do <m>T</m> in the
    <m>(\cB,\cC)</m>-coordinates, and finally convert from
    <m>\cC</m>-coordinates back to standard coordinates.
  </p>

  <bluebox>
    <title>Recipe: Computing <m>T(x)</m> in terms of the <m>(\cB,\cC)</m>-matrix</title>
    <p>
      Suppose that <m>A = [T] = CDB\inv</m> is the standard matrix for <m>T : \R^n\to\R^m</m>,
      where
      <m>B</m> is the invertible matrix corresponding to
      the basis <m>\cB</m> for <m>\R^n</m>,
      <m>C</m> is the invertible matrix corresponding to
      the basis <m>\cC</m> for <m>\R^m</m>,
      and <m>D={}_\cC[T]_\cB</m> is the <m>(\cB,\cC)</m>-matrix for <m>T</m>.
      To compute <m>T(x) = Ax</m>, for some <m>x \in \R^n</m>, one can do the following:
      <ol>
        <li>
          Multiply <m>x</m> by <m>B\inv</m>, which changes to the <m>\cB</m>-coordinates:
          <m>{}_\cB[x] = B\inv x</m>.
          </li>
          <li>
            Multiply this by <m>D</m>: <m>D\;{}_\cB[x] = DB\inv x</m>.
          </li>
          <li>
            Interpreting this vector as a <m>\cC</m>-coordinate vector,
            we multiply it by <m>C</m> to change back to the usual coordinates for <m>\R^m</m>:
            <m>Ax = CDB\inv x = CD{}_\cB[x].</m>
          </li>
        </ol>
      </p>
      <p>
        To summarize: if <m>A = CDB\inv</m>, then <m>A</m> and <m>D</m> do the same thing, only in different coordinate systems for <m>\R^n</m> and <m>\R^m</m>.
      </p>
    </bluebox>

    <specialcase xml:id="bc-matrix-worked-eg">
      <idx><h><m>(\cB,\cC)</m>-matrix</h><h>worked example</h></idx>
      <p>
        Consider the matrices
        <me>
          A = \mat{0 1; 0 1} \quad
          B = \mat{0 -1; 1 0} \quad
          C = \mat{1 1; 1 -1} \quad
          D = \mat{1 0; 0 0}.
        </me>
        One can verify that <m>A = CDB\inv</m>: try it yourself.
        Let <m>v_1 = {0\choose 1}</m> and <m>v_2 = {-1\choose 0}</m>, the columns of <m>B</m> corresponding to the basis <m>\cB = (v_1,v_2)</m> of <m>\R^2</m>.
        Let <m>w_1 = {1\choose 1}</m> and <m>w_2 = {1\choose -1}</m>, the columns of <m>C</m> corresponding to the basis <m>\cC = (w_1,w_2)</m>, another basis of <m>\R^2</m>.
      </p>
      <p>
        The matrix <m>D</m> is diagonal with a one and a zero: it keeps the <m>x</m>-direction and zeroes out the <m>y</m>-direction.
      </p>
      <p>
        To compute <m>Ax</m>, first we multiply by <m>B\inv</m> to find
        the <m>\cB</m>-coordinates of <m>x</m>,
        then we multiply by <m>D</m>,
        then we multiply by <m>C</m>.
        For instance, let <m>\textcolor{seq-green}x = {1\choose 2}</m>.
        <ol>
          <li>
            We see from the <m>\cB</m>-coordinate grid below that
            <m>\textcolor{seq-green}x = 2\textcolor{seq-violet}{v_1} - \textcolor{seq-blue}{v_2}</m>.
            Therefore, <m>B\inv\textcolor{seq-green}x = \textcolor{seq-green}{{}_\cB[x]} = {2\choose -1}.</m>
          </li>
          <li>
            Multiplying by <m>D</m> zeroes out the <m>y</m>-coordinate: <m>\textcolor{seq-red}{D\;{}_\cB[x]} = {2\choose 0}</m>.
          </li>
          <li>
            Interpreting <m>{2\choose 0}</m> as a <m>\cC</m>-coordinate vector,
            we multiply by <m>C</m> to get
            <me>
              \textcolor{seq-red}{Ax} = C\vec{2 0} = 2\textcolor{seq-violet}{w_1}
              = \vec{2 2}.
            </me>
            Of course, this vector lies at <m>(2, 0)</m> on
            the <m>\cC</m>-coordinate grid.
          </li>
        </ol>
        <latex-code>
\begin{tikzpicture}[scale=.8, thin border nodes]
  \draw[help lines] (-3,-3) grid (3,3);
  \node at (0, 3.5) {$\cB$-coordinates};

  \draw[seq-violet, vector, opacity=.5] (0,0) -- (1,0);
  \draw[seq-blue,   vector, opacity=.5] (0,0) -- (0,1);

  \draw[seq-green, vector] (0, 0) to["{${}_\cB[x]$}" above right] (2, -1);
  \point at (0, 0);

  \begin{scope}[xshift=9cm]
    \draw[help lines] (-3,-3) grid (3,3);
    \node at (0, 3.5) {usual $\cE_n$-coordinates, $n=2$};

    \draw[seq-violet, vector, opacity=.5] (0,0) -- (0,1);
    \draw[seq-blue,   vector, opacity=.5] (0,0) -- (-1,0);

    \draw[seq-green, vector] (0, 0) to["$x$" below right] (1, 2);
    \point at (0, 0);

  \end{scope}

  \begin{scope}[yshift=-9cm]
    \draw[help lines] (-3,-3) grid (3,3);
    \node at (0, 3.5) {$\cC$-coordinates};

    \draw[seq-violet, vector, opacity=.5] (0,0) -- (1,0);
    \draw[seq-blue,   vector, opacity=.5] (0,0) -- (0,1);

    \draw[seq-red, vector] (0, 0) to["${D\;{}_\cB[x]}$"] (2, 0);
    \point at (0, 0);

  \end{scope}

  \begin{scope}[xshift=9cm,yshift=-9cm]
    \draw[help lines] (-3,-3) rectangle (3,3);
    \node at (0, 3.5) {usual $\cE_m$-coordinates, $m=2$};
    \path[clip] (-3, -3) rectangle (3, 3);
    \begin{scope}[cm={(1,1,1,-1,(0,0))}, scale=.7]
      \draw[help lines] (-5,-5) grid (5,5);
      \draw[seq-violet, vector, opacity=.5] (0,0) -- (1,0);
      \draw[seq-blue,   vector, opacity=.5] (0,0) -- (0,1);

      \draw[seq-red, vector] (0, 0) to["${Ax=CDB^{-1}x}$"] (2, 0);
      \end{scope}
    \point at (0, 0);
  \end{scope}

  \draw[->, shorten=2mm, thick] (6, 1) to[bend right]
    node[above=1mm] {multiply by $B\inv$} (3, 1);
  \draw[->, shorten=2mm, thick] (3, -10) to[bend right]
    node[below=1mm] {multiply by $C$} (6, -10);
  \draw[->, shorten=2mm, thick] (-1, -3) to[bend right]
    node[right=1mm] {multiply by $D$} (-1, -5);
  \draw[->, shorten=2mm, thick, xshift=11cm] (1, -3) to[bend left]
    node[left=1mm] {multiply by $A$} (1, -5);

\end{tikzpicture}
        </latex-code>
        To summarize:
        <ul>
          <li>
            <m>D</m> retains the <m>e_1</m>-direction
            and zeroes out the <m>e_2</m>-direction.
          </li>
          <li>
            <m>A</m> maps <m>v_1</m>-direction onto the <m>w_1</m>-direction
            and maps the <m>v_2</m>-direction to zero.
          </li>
        </ul>
      </p>
    </specialcase>

  <fact hide-type="true">
    <title>Facts about <m>(\cB,\cC)</m>-matrices</title>
    <statement>
      <p>
        Let <m>T : \R^n\to\R^m</m> and <m>U : \R^p\to\R^n</m> be linear transformations,
        and let <m>\cB,\cC,\cD</m> be bases for <m>\R^p,\R^n,\R^m</m>, respectively.
        Then:
        <ol>
          <li>
            <m>{}_\cD[T(v)] = {}_\cD[T]_\cC \; {}_\cC[v]</m> for any <m>v\in\R^n</m>.
          </li>
          <li>
            <m>{}_\cD[T \circ U]_\cB = {}_\cD[T]_\cC
            \; {}_\cC[U]_\cB</m>
          </li>
          <li>
            If <m>T</m> is invertible (so <m>n=m</m>),
            then <m>{}_\cC[T^{-1}]_\cD = ({}_\cD[T]_\cC)^{-1}</m>.
          </li>
        </ol>
      </p>
    </statement>
    <proof>
      <p>
        <ol>
          <li>
            <m>{}_\cD[T(v)] = D^{-1}(T(v)) = D^{-1}[T]v
            = D^{-1}[T]CC^{-1}v = {}_\cD[T]_\cC \; {}_\cC[v]</m>
          </li>
          <li>
            <m>{}_\cD[T \circ U]_\cB = D^{-1}[T][U]B
            = D^{-1}[T]CC^{-1}[U] = {}_\cD[T]_\cC \; {}_\cC[U]_\cB</m>
          </li>
          <li>
            This follows directly from 2:
            <m>{}_\cC[T^{-1}]_\cD \; {}_\cD[T]_\cC = {}_\cC[T^{-1} \circ T]_\cC
            = {}_\cC[\Id_{\R^n}]_\cC = I_n</m>.
          </li>
        </ol>
      </p>
    </proof>
  </fact>

  <theorem xml:id="rank-normal-form">
    <statement>
      <p>
        Suppose <m>T : \R^n \to \R^m</m> is a linear map.
        Then we can pick bases, <m>\cB</m> for <m>\R^n</m>
        and <m>\cC</m> for <m>\R^m</m>, relative to which the
        <m>(\cB,\cC)</m>-matrix for <m>T</m> is diagonal with <m>\rank(T)</m>
        ones and zeroes everywhere else:
        <me>{}_\cC[T]_\cB = \mat[c]{1 0 \cdots, 0; 0 1 \cdots, 0;
              \vdots, \vdots, \ddots, \vdots; 0 0 \cdots, 0}.</me>
      </p>
    </statement>
    <proof>
      <p>
        This is essentially just another application of the
        <xref ref="linindep-pivot-cols"/>.
        If <m>A</m> is the standard matrix for <m>T</m>, say,
        <!-- https://ulrikbuchholtz.dk/ila/demos/rrinter.html?mat=1,2,0,3:0,0,1,-1:0,0,0,0&ops=r1:2:2,r1:-1:0,r0:2:1,r0:-1:2&cur=4 -->
        <me>
          A = \mat{1 2 -1 4; 2 4 -1 7; -1 -2 3 -6}
          \quad\xrightarrow{\text{RREF}}\quad\mat{1 2 0 3; 0 0 1 -1; 0 0 0 0},
        </me>
        then we take the pivot columns of <m>A</m> (here, the first and third columns),
        as these form a basis for the image, and extend to a basis for all of <m>\R^m</m>,
        again using the pivotal theorem. In the example, we get:
        <me>
          \cC = \left(\vec{1 2 -1},\vec{-1 -1 3},\vec{1 0 0}\right)
        </me>
        To get <m>\cB</m>, we pick the standard basis vectors corresponding to the
        pivot columns of <m>A</m> and extend that a basis for all <m>\R^n</m>
        by appending a basis for the kernel of <m>T</m>,
        which we find using the RREF of its standard matrix. Here we get:
        <me>
          \cB = \left(\vec{1 0 0 0},\vec{0 0 1 0}, \vec{-3 0 1 1},
          \vec{-2 1 0 0}\right)
        </me>
        It's easy to see that this works, and we can check this by forming the matrices
        corresponding to <m>\cB</m> and <m>\cC</m> and computing:
        <me>
          \begin{split}
          {}_\cC[T]_\cB \amp= C^{-1}AB = \mat{1 -1 1;2 -1 0;-1 3 0}^{-1}
          \mat{1 2 -1 4; 2 4 -1 7; -1 -2 3 -6}
          \mat{1 0 -3 -2; 0 0 0 1; 0 1 1 0; 0 0 1 0} \\
          \amp= \mat{1 0 0 0; 0 1 0 0; 0 0 0 0}.
          \end{split}
        </me>
      </p>
    </proof>
  </theorem>

  <p>
    This is a very simple kind of diagonalisation theorem,
    which is made possible by the fact that we can choose bases
    for the domain and the codomain independently.
    In <xref ref="chap-eigenvalues"/> we'll see that the situation is much more subtle
    for linear transformations <m>T : \R^n \to \R^n</m> where the domain and
    the codomain coincide and we want to use the <em>same</em> basis for both.
  </p>

  <!--
      <p>TODO: general vector spaces? examples! passive versus active transformations.</p>
  -->
</section>
